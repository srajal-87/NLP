{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0a18e30",
   "metadata": {},
   "source": [
    "## stemming\n",
    "### In Natural Language Processing (NLP), stemming is the process of reducing words to their base or root form. The idea is to strip away prefixes and suffixes (like \"ing\", \"ly\", \"es\", \"s\", etc.) to get to the word's stem. This helps in various NLP tasks like text mining, information retrieval, and search engines by normalizing words to their root form, making it easier to analyze and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "def6473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PortStemmer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba3ee7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['eats','eating','eates','goes','going','gone','finally','takeing','moving','moves','history','completion','morning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12a6b924",
   "metadata": {},
   "outputs": [],
   "source": [
    " pstemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a353ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## root_word=[pstemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a6cd728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eats------>eat\n",
      "eating------>eat\n",
      "eates------>eat\n",
      "goes------>goe\n",
      "going------>go\n",
      "gone------>gone\n",
      "finally------>final\n",
      "takeing------>take\n",
      "moving------>move\n",
      "moves------>move\n",
      "history------>histori\n",
      "completion------>complet\n",
      "morning------>morn\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+'------>'+pstemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c5a197b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regex-based Stemmer\n",
    "## regexp (str or regexp) â€“ The regular expression that should be used to identify morphological affixes.\n",
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db418604",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = RegexpStemmer('ing$|s$|e$|able$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "357e085f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eats------>eat\n",
      "eating------>eat\n",
      "eates------>eate\n",
      "goes------>goe\n",
      "going------>go\n",
      "gone------>gon\n",
      "finally------>finally\n",
      "takeing------>take\n",
      "moving------>mov\n",
      "moves------>move\n",
      "history------>history\n",
      "completion------>completion\n",
      "morning------>morn\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+'------>'+st.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ba6e979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meaningful------>manful\n",
      "suspicious------>upiciou\n",
      "willingness------>willn\n",
      "unableness------>unn\n"
     ]
    }
   ],
   "source": [
    "## $-> end->remove matching suffix  ($)->then it will remove matching inffix\n",
    "st = RegexpStemmer('ing|s|e|able', min=4) -> # these are all affix(an affix is a morpheme (the smallest grammatical unit in a language) that is attached to a word stem to form a new word or word form.)\n",
    "new_word=['meaningful','suspicious','willingness','unableness']\n",
    "for word in new_word:\n",
    "    print(word+'------>'+st.stem(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7521ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af62ce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowst=SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1015ae02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eats------>eat\n",
      "eating------>eat\n",
      "eates------>eat\n",
      "goes------>goe\n",
      "going------>go\n",
      "gone------>gone\n",
      "finally------>final\n",
      "takeing------>take\n",
      "moving------>move\n",
      "moves------>move\n",
      "history------>histori\n",
      "completion------>complet\n",
      "morning------>morn\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+'------>'+snowst.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab15263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
